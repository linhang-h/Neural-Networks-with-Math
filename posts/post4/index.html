<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/Neural-Networks-with-Math/libs/katex/katex.min.css"> <link rel=stylesheet  href="/Neural-Networks-with-Math/css/franklin.css"> <link rel=stylesheet  href="/Neural-Networks-with-Math/css/style.css"> <link rel=icon  type="image/png" sizes=32x32  href="/Neural-Networks-with-Math/assets/images/network.png"> <title>Introduction to G-CNNs</title> <header> <nav> <div class=nav-content > <div class=logo > <a href="/Neural-Networks-with-Math/">Neural Networks with Math</a> </div> <ul class=nav-links > <li><a href="/Neural-Networks-with-Math/">Home</a> <li><a href="/Neural-Networks-with-Math/menu1">Posts</a> <li><a href="/Neural-Networks-with-Math/people">People</a> </ul> </div> </nav> <script> let nav = document.querySelector("nav"); window.onscroll = function() { if(document.documentElement.scrollTop > 20){ nav.classList.add("sticky"); }else { nav.classList.remove("sticky"); } } </script> </header> <div class="container py-3 px-3 mx-auto"><div class=franklin-content > <h1 id=group_equivariant_neural_networks ><a href="#group_equivariant_neural_networks" class=header-anchor >Group Equivariant Neural Networks</a></h1> <p>This webpage consists of a set of notes we created while going through the course <em>An Introduction to Group Equivariant Deep Learning</em> by Erik Bekkers at the University of Amsterdam. The course materials are freely available online at <a href="https://uvagedl.github.io/">uvagedl</a>, and the lecture series is available as a public <a href="https://www.youtube.com/playlist?list&#61;PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd">playlist</a> on YouTube. We owe our deepest gratitude for <em>Dr.</em> Erik Bekkers and all other people who created this wonderful course and made the materials publically available. We largely follow the structure of these lectures, even though some of the mathematical details are our own takes on the original arguments. The intrigued reader is highly recommended to check out the original lectures, where concepts are illustrated with many amazing graphics. We hope to duely justify the slogan &#39;<em>Group convolution is all you need</em>&#39; through this short digest. </p> <div class=franklin-toc ><ol><li><a href="#introduction">Introduction</a><li><a href="#g-cnn_the_first_class"><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-CNN: The First Class</a><li><a href="#representation_theory_and_harmonic_analysis_on_locally_compact_groups">Representation Theory and Harmonic Analysis on Locally Compact Groups</a><li><a href="#g-cnn_regular_vs_steerable_networks"><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-CNN: Regular v.s. Steerable Networks</a><li><a href="#g-gnn_equivariant_graph_neural_networks"><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-GNN: Equivariant Graph Neural Networks</a></ol></div> <h2 id=introduction ><a href="#introduction" class=header-anchor >Introduction</a></h2> <p>Convolutional Neural Networks &#40;CNNs&#41; possess the distinguishing property of translation invariance in their convolutional layers, allowing them to maintain the inherent spatial structure of image data. This characteristic enables CNNs to excel in various complex tasks, including edge detection, feature extraction for object recognition, and semantic segmentation.</p> <p>However, image data often come with additional structures, such as rotational or reflectional symmetries, which are not built-in symmetries of traditional CNNs. Group-equivariant CNNs &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-CNNs&#41; extend the translation-invariance property of traditional CNNs into equivariance of more general symmetry groups, such as rotations, reflections, or scaling transformations. This is achieved by defining convolutional layers over topological groups rather than the usual vector space <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant=double-struck >R</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">\mathbb{R}^n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6889em;"></span><span class=mord ><span class="mord mathbb">R</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span>. As a result, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-CNNs efficiently represents and processes data with a lot of symmetries, in many cases improving the performance margin significantly. One of the first applications where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-CNNs are extremely useful is medical imaging, where cells and organs can appear in various orientations &#40;&#91;Bekkers et.al. 2018&#93;&#41;. </p> <p>&#33;&#33;&#33;TBA</p> <h2 id=g-cnn_the_first_class ><a href="#g-cnn_the_first_class" class=header-anchor ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-CNN: The First Class</a></h2> <p>Say we want to build a network which recognizes the letter <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>. Regardless of where we position the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> in our input image, we want the feature map of the network to activate in the same way where it detects the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> somewhere in the image. This sort of <em>translation equivariance</em> is a defining feature of Convolutional Neural Networks &#40;CNNs&#41;, and in fact what makes it so useful in pattern recognition tasks, especially in image and spatial data. </p> <p>CNNs achieve translation invariance through the structure of their convolutional layers. Mathematically, a convolutional layer computes a feature map <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> as <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>k</mi><mo>∗</mo><mi>I</mi><mo stretchy=false >)</mo><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><msub><mo>∫</mo><msup><mi mathvariant=double-struck >R</mi><mi>n</mi></msup></msub><mi>k</mi><mo stretchy=false >(</mo><mi>u</mi><mo stretchy=false >)</mo><mi>I</mi><mo stretchy=false >(</mo><mi>x</mi><mo>−</mo><mi>u</mi><mo stretchy=false >)</mo><mtext> </mtext><mi>d</mi><mi>u</mi></mrow><annotation encoding="application/x-tex">(k * I)(x) = \int_{\mathbb{R}^n} k(u) I(x - u) \, du</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >∗</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mclose >)</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1.1608em;vertical-align:-0.3558em;"></span><span class=mop ><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0006em;">∫</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1264em;"><span style="top:-2.3442em;margin-left:-0.1945em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathbb mtight">R</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.5935em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3558em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mopen >(</span><span class="mord mathnormal">u</span><span class=mclose >)</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">u</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span></span></span></span>, where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo stretchy=false >(</mo><mi>u</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">k(u)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mopen >(</span><span class="mord mathnormal">u</span><span class=mclose >)</span></span></span></span> is the kernel &#40;filter&#41;, and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">I(x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span></span></span></span> is the input. If the input is translated by a vector <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>∈</mo><msup><mi mathvariant=double-struck >R</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">t \in \mathbb{R}^n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6542em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">t</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6889em;"></span><span class=mord ><span class="mord mathbb">R</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span>, such that <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>I</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mi>I</mi><mo stretchy=false >(</mo><mi>x</mi><mo>−</mo><mi>t</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">I&#x27;(x) = I(x - t)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0019em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class=mclose >)</span></span></span></span>, the resulting feature map shifts correspondingly: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mo stretchy=false >(</mo><mi>k</mi><mo>∗</mo><msup><mi>I</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup><mo stretchy=false >)</mo><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo>=</mo><mi>f</mi><mo stretchy=false >(</mo><mi>x</mi><mo>−</mo><mi>t</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">f&#x27;(x) = (k * I&#x27;)(x) = f(x - t)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0019em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >∗</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1.0019em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mclose >)</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class=mclose >)</span></span></span></span>. This demonstrates that the convolution operation is <em>compatible with translational symmetries</em>. </p> <p>Our physical world is brimming with symmetries – from the discrete polytopal symmetries of a virus to the rotational symmetries of the surface of a planet. It is an inevitable result that the data inputted in neural networks </p> <h2 id=representation_theory_and_harmonic_analysis_on_locally_compact_groups ><a href="#representation_theory_and_harmonic_analysis_on_locally_compact_groups" class=header-anchor >Representation Theory and Harmonic Analysis on Locally Compact Groups</a></h2> <h2 id=g-cnn_regular_vs_steerable_networks ><a href="#g-cnn_regular_vs_steerable_networks" class=header-anchor ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-CNN: Regular v.s. Steerable Networks</a></h2> <h2 id=g-gnn_equivariant_graph_neural_networks ><a href="#g-gnn_equivariant_graph_neural_networks" class=header-anchor ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span>-GNN: Equivariant Graph Neural Networks</a></h2> <div class=page-foot > Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. <a href="https://www.flaticon.com/free-icons/machine-learning" title="machine learning icons">Machine learning icons created by Freepik - Flaticon</a> </div> </div> </div>